% !TeX program = lualatex
% !TeX encoding = UTF-8
% !TeX root = ./thesis.tex

\section{Higher Order Logic Programming}

At the beginning of our work it was decided that the this project should be implemented using $\lambda$Prolog and ELPI, one of its implementations which allows for more flexibility (\eg optional type declarations) more functionality (\eg constraint programming, which will be useful in later phases of the project) and also improved performances compared to other major implementations of $\lambda$Prolog.

As a programming language $\lambda$Prolog is naturally a good fit for a binder-heavy project like our as it natively offer all the functionality required to handle $\alpha$-equivalence, capture avoiding substitutions and higher-order unification; moreover the high level abstractions and backtracking allow for almost a 1-1 encoding of inference rules. As an example  below we can see the comparison between a natural deduction inference rule and a $\lambda$Prolog clause in the case of $\Pi$-Introduction.
In natural deduction style we have the following inference rule
\[
\begin{prooftree}
\hypo{C(x)\ set\ [x \in B]}
\hypo{B\ set}
\infer{2}[\ensuremath{\Pi}-F]{\Pi_{x\in B}{C(x)}\ set}
\end{prooftree}\]
while in $\lambda$Prolog we would write
\begin{verbatim}
ofType (setPi B C) KIND3 IE
    :- ofType B KIND1 IE
    ,  (pi x\ locDecl x B
        => ofType (C x) KIND2 IE)
    ,  pts_fun KIND1 KIND2 KIND3
    .
\end{verbatim}
where \verb|ofType| represent the $set$ judgement, \verbl{locDecl} is used to locally introduce hypothesis in the context and \verb|pts_fun| is used to decide whether the produced type is a set or a collection. 

While the $\lambda$Prolog version is more verbose it should be noted that this one rule encode the $\Pi$-Formation rule for both the extensional and the intensional level and also for all combination of arguments kinds between sets, collections, propositions and small proposition.

\subsection{Changes to the calculus}
As pointed out in the introduction before we could begin the implementation we had to apply some changes to the calculi exposed in \cite{maietti2009minimalist}.

	\subsubsection{Syntax Directed Rules}
	Between the rules of \emph{mTT} and \emph{emTT} there is a rule which states that equal type have the same elements, that is:
	\[
	\begin{prooftree}
	\hypo{a \in A}
	\hypo{A = B}
	\infer2[conv]{a\in B}
	\end{prooftree}
	\]
 	
 	This rule is problematic from an implementation point of view since it can be triggered at any moment and (at the extensional level) would start a proof search trying to prove $A=B$ for a unknown $A$. A simple solution is to preemptively compose this rule to all other rule that might need it; for example we can see that the elimination rule for dependents products changes from 
 	\[
 	\begin{prooftree}
	\hypo{f\in \Pi_{x\in B}{C(x)}}
	\hypo{t \in B}
	\infer2[\ensuremath{\Pi}-E]{\s{apply}(f,t)\in C(t)}
 	\end{prooftree}
 	\]
 	to 
 	\[
 	\begin{prooftree}
 	\hypo{f\in \Pi_{x\in B}{C(x)}}
 	\hypo{t \in B'}
 	\hypo{B=B'}
 	\infer3[\ensuremath{\Pi}-E]{\s{apply}(f,t)\in C(t)}
 	\end{prooftree}
 	\]
 	 the main difference being that in the syntax directed version we check that the domain type of $f$ and the inferred type of $t$ are convertible instead of requiring syntactic equality like in the original rule. In this way the power of the calculus is surely not increased as the syntax directed rule is admissible in the calculus with the two previous rules, indeed
 	\[\begin{prooftree}
 	\hypo{f\in \Pi_{x\in B}{C(x)}}
 	\hypo{t \in B'}
 	\hypo{B=B'}
 	\infer2[conv]{t \in B}
 	\infer2[\ensuremath{\Pi}-E]{\s{apply}(f,t)\in C(t)}
 	\end{prooftree}\]
 	is a derivation of the same judgement from the same hypothesis.
 	
 	For this change to be effective we also need to reformulate the conversion rules given by the calculi (\eg $\s{apply}(\lambda^B x. f,t) = f\{t/x\} $) in directed rules describing a reduction predicate $\rhd$ (\eg  $\s{apply}(\lambda^B x. f,t) \rhd f\{t/x\} $) from which we will define equality as reducibility to a common term, which is equivalent to the original equality given that both calculi of the Minimalist Foundation have both the property of Church-Rosser confluence and strong normalization. This new relation will be implemented by the predicate \verb|conv|.
 	
 	The full modifications to the calculi in our implementation with respect to making the rule syntax directed are mostly about checking for convertibility/equality where mTT/emTT require syntactical equality. We plan to provide a full proof of the validity of this modification, and also of the followings, in Abella in the future.
	
	

\subsubsection{Informative Proof-terms at the Extensional Level and Exstensional Equality}
	\[\begin{prooftree}
	\hypo{b\in B}
	\hypo{\s{true} \in C(b)}
	\hypo{C(x)\ prop\ [x \in B]}
	\infer3[\ensuremath{\exists}-\ensuremath{\text{I}}]{\s{true} \in \exists_{x\in B}{C(x)}}
	\end{prooftree}\quad
	\begin{prooftree}
	\hypo{\s{true}\in \s{Eq}(A,a,b)}
	\infer1[Eq-E]{a = b \in A}
	\end{prooftree}\]
	In the calculus emTT a token proof term $\s{true}$ is used to represent all proofs of propositions and small propositions; this poses problems during the interpretation when we need to construct intensional proof terms given only the token $\s{true}$. Moreover the strong elimination rule for the propositional extensional equality turns every conversion in an undecidable problem of general proof search for ${\s{true}\in \s{Eq}(A,a,b)}$.
	To reasonably implement the extensional calculus and the interpretation we need a way to construct  intensional proofs from extensional proof and a way to contain the undecidability of the strong elimination rule for the extensional propositional equality.
	
	A first approach to the problem could have been to have both the extensional type checker and the interpretation work on full derivations; this is the method chosen by Maietti in \cite{maietti2009minimalist} and would solve the problems regarding the missing informations in the extensional calculus and language, but was discarded as a solution because from an implementation standpoint the code to encode a derivation would be almost a copy of the code needed to encode terms, yet with subtle, but non trivial, differences.
	
	The chosen solution was to both add informative proof terms to the extensional level and weaken the elimination rule of the propositional extensional equality. The first part of the solution makes the extensional rule for proposition more similar to the intensional ones 
	\[
	\begin{prooftree}
	\hypo{b\in B}
	\hypo{p \in C(b)}
	\hypo{C(x)\ prop\ [x \in B]}
	\infer3[\ensuremath{\exists}-\ensuremath{\text{I}}]{<b,_{\exists}\  p> \in \exists_{x\in B}{C(x)}}
	\end{prooftree}
	\]
	so that during the interpretation more informations are available.
	
	The second part modifies the extensional propositional equality elimination rule to a weaker but equivalent form; the rule
	\[
	\begin{prooftree}
		\hypo{\s{true}\in \s{Eq}(A,a,b)}
		\infer1[Eq-E]{a = b \in A}
	\end{prooftree}
	\]
	becomes
	\[
	\begin{prooftree}
	\infer0[Eq-E]{a = b \in A\ [{\s{h}\in \s{Eq}(A,a,b)}]}
	\end{prooftree}
	\]	
	This weaker form has nicer computational properties, the most important one being that it is always deterministic and terminating to check if it is possible to apply given a specific context while still allowing to locally definitions in a context via implication or dependents types.
	
	A drawback of this solution is that it is complex to use even simple lemmas; to this problem we offer two solutions: to manually use the cut elimination of the calculus or to introduce a new \emph{let in} construct \[\s{let}\ x\ :=\ t_1 \in T\ \s{in}\ t_2\] used to introduce locally typed definitions.
	
	As of this writing this \emph{let in} in not yet implemented as there many different ways the needed functionality can be obtained each with different compromises and it is not entirely clear which implementation method is the most adeguate to our project. In our simple cases it is acceptable to manually perform the cut elimination to locally include the desired lemma so we plan to implement a proper \emph{let in} once there is a strong need for it.

\subsubsection{$\xi$-Rule}
	Another difference between the calculus in Maietti's work and ours is that our model validates the $\xi$-rule at the intensional level, removing it would require a syntax directed rule for explicit substitution.	
%\subsubsection{Code Reuse}
%	As already hinted above when discussing some of the qualities of $\lambda$Prolog 

\section{The Interpretation}
	One of the main result of \cite{maietti2009minimalist} is a categorical proof of the validity of an interpretation of an extensional type theory into an intensional one. 
	
	In particular first a quotient model Q(mTT) is built on the theory mTT, this model is given as a category where objects are pairs of $(A, =_A )$ (abbreviated to $A_=$ when $=_A$ it is clear from the context) where A is an intensional type called {support} and \[ x =_A y \ props\ [x\in A,\ y \in A]\] is an equivalence relation on $A$; which means that there are terms $\s{rfl}_A$, $\s{symm}_A$ and $\s{tra}_A$ such that the following judgements hold in mTT
	\begin{align*}
	\s{rfl}_A(x) \in x& =_A x\ [x\in A]\\
	\s{sym}_A(x,y,u) \in y & =_A x\ [x\in A,\ y\in A,\ u \in x =_A y ]\\
	\s{tra}_A(x,y,z,u,v) \in x & = _A z\ [x \in A,\ y \in A,\ z \in A,\ u \in x =_A y, v \in y =_A z ]
	\end{align*}
	In the following we will refers to the objects of Q(mTT) as setoids.
	
	The morphisms of Q(mTT) from $(A,\ =_A)$ to $(B,\ =_B)$  are all the well-typed terms of mTT \[ f(x) \in B(x) \ [x\in A]\] that preserve the setoid equality, that is there exist a proof-term \[\s{pr_1}(x,y,z) \in f(x) =_B f(y)\ [x \in A,\ y \in A,\ z \in x =_A y ]\]
	Equality between two morphisms f,g : $(A,=_A ) \to (B,=_B )$ holds if they maps equal elements of $A_=$ to equal elements of $B_=$, that is if there is a proof-term \[\s{pr_2}(x) \in f(x) =_B g(x)\ [x \in A]\]
	
	Starting from the category Q(mTT) we can define also \emph{dependent setoids}, given a setoid $A_=$ we say that \[B_=(x)\ [x\in A_=] \]	 is a dependent setoid if its support is a dependent type \(B(x)\ type\ [x \in As]\), if its relation is a dependent proposition \[ y =_{B(x)} y'\ [x \in A,\ y \in B(x),\ y' \in B(x)]\] and if there is a substitution morphism \[\sigma^{x_2}_{x_1}(d,y)\in{}B(x_2)\ [x_1 \in A,\ x_2 \in A,\ d \in x_1 =_A x_2 ,\ y \in B(x_1)]\] that satisfies the properties given by definition 4.9 in \cite{maietti2009minimalist}, that is it needs to preserve the equality of $B_=$, to be proof-irrelevant by not depending on the particular choice of the proof-term $d\in x_1=x_2$ (so that we can write $\sigma^{x_2}_{x_1}(y)$ in place of $\sigma^{x_2}_{x_1}(d,y)$), there need to always exists the identity substitution
		\footnote{Which in general does not need to be the identity morphism, for example 
			\[\sigma^{x}_{x}(\s{rfl}_A(x),w) \equiv
			 \s{elim}_+(
			 	w
			 	,(z).\s{inl}(\sigma^{x}_{x}(\s{rfl}_A(x)(x),z))
			 	,(z).\s{inr}(\sigma^{x}_{x}(\s{rfl}_A(x)(x),z))
			 )
			\] if $w \in  B+C\ [x\in A]$
		}
	$\sigma^{x_1}_{x_1}(\s{rfl}_{B(x_1)}(x_1), \text\textendash)$ and lastly substitution morphisms need to be composable, that is we require \[\sigma^{x_3}_{x_2}(\sigma^{x_2}_{x_1}(y)) =_{B(x_3)} \sigma^{x_3}_{x_1}(y)\] in the appropriate context\footnote{It is worth noting that in the Minimalist Foundation the only type that directly takes terms as arguments are the propositional equalities (written $\s{Eq}$ and $\s{Id}$ in emTT and mTT respectively). For any $B(x)\ type\ [x\in A]$ the only possible occurrences of $x$ are as an argument of $\s{Eq}$ (resp.\ $\s{Id}$ if in mTT), together with the absence of strong elimination of terms towards types this means that conversion of types is always only reduced to conversion of terms and that types containing no propositions cannot be truly dependent. For example the canonical way to construct a type \emph{list of type $C$ of length $n$} is via a dependent sum $\Sigma(\s{List}(C),(l).P(l,n))$ where $P(l,n)$ is the proposition \emph{length of $l$ equals $n$}.}.
	
	Over these substitution we can define \emph{canonical isomorphism} between two type $B_1$ and $B_2$ as the only $\sigma$ between them. In our code we have implemented these isomorphisms as with the predicate \verb|tau B B' P|.

	The reason these construction are needed is because the strong elimination rule of the extensional propositional equality can derive a judgemental equality from just an hypothetical assumption. For an example we can see that a judgement like $\s{true} \in \s{Eq}(C,c,d)\ [c \in C, d\in C]$ is a well formed but not derivable judgement in emTT, but if we add one more assumption to the context we obtain \[\s{true} \in \s{Eq}(C+C,\s{inl}(c),\s{inl}(d))\ [c \in C, d\in C, h\in \s{Eq}(C,c,d)]\] which is derivable since we can use the rules $\s{prop-true}$ and {E-Eq} to derive the judgement $c\eg d\in C$ from the given context.
	
	This can be seen also in the fact that this judgement\begin{multline*}
		\forall_{x\in\singleton}\forall_{f\in\Pi(\s{Eq}(\singleton,x,\star),\singleton)}\s{Eq}(\singleton,\star,x)\Rightarrow\\ \s{Eq}(\singleton,\s{apply}(f,\s{eq}(\singleton,\star)),\s{apply}(f,\s{eq}(\singleton,\star)))\ \ props\footnote{$\s{eq}(A,a)$ is the proposed canonical constructor from our implementation that replaces $\s{true}$ in the introduction rule 
			\[
			\begin{prooftree}
			\hypo{\c\in{}C}
			\infer1{\s{true}\in\s{Eq}(C,c,c)}
			\end{prooftree}
			\]
		}
	\end{multline*}
	is derivable in the empty context even if there is a mismatch between the types of $f$ and $\s{eq}(\singleton,\star)$. Here for example we would want to apply a canonical isomorphism to $\trad{\s{eq}(\singleton,\star)}$\footnote{In this work we use the double bracket notation for the interpretation instead of the $\textendash^\text{I}$ used in \cite{maietti2009minimalist}} so that its type match with the domain of $\trad f$; after the correction we obtain $\s{apply}(f, \tau_{\trad{\s{Eq}(\singleton,\star,\star)}}^{\trad{\s{Eq}(\singleton,x,\star)}}(\trad{\s{eq}(\singleton,\star)}))$ which is well-typed in mTT 
	
	
	From this introduction to the structure of the interpretation we can see that the method used to force the semantics of emTT on mTT (via Q(mTT)) is to require the creation of suitable proof terms thus restricting the available language to a subset that preserve the extensional semantic. 
	
	We can se another more explicit application of this method in the interpretation of dependent products, indeed in this case  a function term of emTT is interpreted as a pair whose first projection is an intensional function and whose second projection is a proof that the first projection preserves the setoid equalities of Q(mTT).

	From the point of view of the implementation this means that we have to produce various proof for each of the type constructor we wish to include in our implementation.
	
	As of now we have implemented all that is needed to fully interpret the subset of emTT comprised of singletons, dependent products, implications, universal quantifications, propositional equality. We believe that this subset exhibit enough of the complexity of the interpretation and feel confident that the structure of our implementation will be able to cover also the needs of the remaining constructors. 

\section{The Code}
	All the code was written in $\lambda$Prolog (in particular it was written for the ELPI implementation \cite{dunchev2015elpi} of $\lambda$Prolog) and make extensive use of many high level features that in other languages would not be available. Still our code does not use many of the more advanced features offered by ELPI like constraint programming which we plan to use in the next phase of the project when we will start to implement a kernel for the planned proof checker

	In this section we will show some extract of the code and explain how we obtained the desired functionalities.
	\subsection{Project Structure and Extensibility}
		We have divided the code 4 categories \verb|main|, \verb|calc|, \verb|test|, \verb|debug|.
		The first, \verb|main| holds type declaration for the other modules and define the general functionality of the theory shared by all type constructor of both levels.
		the second is a folder containing a \verb|.elpi| file for each type constructor; in each of these files we implement the typing and conversion rules for that particular type constructor. For example in \verb|calc/setPi.elpi| we keep all definitions related to dependent products, like the implementation of $\Pi$-I or the interpretation of a function term.
		\begin{verbatim}
		of (lambda B F) (setPi B C) IE
		    :- spy (ofType B _ IE)
		    ,  spy (pi x\ locDecl x B => isa (F x) (C x) IE)
		    .		
		\end{verbatim}
		\lstinline|pippo flauto|
		The last two, \verb|test| and \verb|debug|,  hold utilities to quickly test the predicates from \verb|main| and \verb|calc| and predicates to inspect the runtime behaviour of the type checking and og the interpretation.
	\subsection{Level and Kind Generic Predicates}
		
